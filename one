import pathlib
import re
import textwrap

import google.ai.generativelanguage as glm
import google.generativeai as genai
import google.generativeai as genai
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pandas as pd
import requests
import seaborn as sns
import tqdm
from sklearn.cluster import KMeans
from sklearn.datasets import fetch_20newsgroups
from sklearn.manifold import TSNE
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay


def summonai():
    # Configure the AI API
    genai.configure(api_key="AIzaSyC5DY8BA0azpk93NxlhDC-1j36Hy69SlLQ")  ### this ur key

    # Function to load data from a JSON file
    def load_data_from_json(file_path):
        try:
            return pd.read_json(file_path)
        except Exception as e:
            print(f"Error loading JSON data: {e}")
            return None

    # Function to analyze data with AI
    def analyze_data_with_ai(loaded_data, model):
        # Converting data summary into a string for the AI prompt
        data_summary = loaded_data.describe().to_string()
        prompt = f"Given the following data summary:\n{data_summary}\nCompile python code that can be executed as you provide it. it must be well thought and use a calculator. consider all types of  machine learning or neural network modeling and transfer learning. respond only with accurate code that is free of any error, written fully and norhing ommited. this is a direct to customer response so do not expect them to code.  provide the highest scoring in precision and accuracy. fully configured for optimal performance. the data will be either json or csv and the code should seamlessly handle either. i also want the compiled code to print the results after it runs .provide only  code now."
        response = model.generate_content(prompt)
        ##this writes it to the liquid variable
        with open("prophitdicemodel.txt", "w") as f:
            f.write(str(response.text.split("\n")[1:-2]))
            f.close()
        print(response.text)
        return response.text

    ###this executes it as a subproocess
    def run_prophitdicemodel():
        with open("prophitdicemodel.txt", "r") as f:
            prophitdicemodel_code = f.read()
            whatsmyfoxsay = exec(
                prophitdicemodel_code)  ## this part acutally runs it  we can make this a var to see it in actions
            print(whatsmyfoxsay)  ## now we get the stuff visually but not good to do for real because will lag u
            f.close()
        return prophitdicemodel_code

    def lets_talk(file_path):
        # Load and prepare data
        loaded_data = load_data_from_json(file_path)
        if loaded_data is None:
            return

        genai_model = genai.GenerativeModel('gemini-pro')
        ###2 bots oohh ok

        ai_recommendation = analyze_data_with_ai(loaded_data, genai_model)
        print("AI Model Recommendation:", ai_recommendation)
        launch_the_ai = run_prophitdicemodel()
        print(launch_the_ai)
        model = genai.GenerativeModel('gemini-pro')
        response = model.generate_content(
            "return the mse and accuracy of the model." + run_prophitdicemodel() + "print the results including the preddicted result and the acutal result as a table of atleadt 10 rows", stream=True)
        for chunk in response:
            print(chunk.text)

        return ai_recommendation

    #################################33


    # Call the main function with the path to your data file
    lets_talk('data.json')

